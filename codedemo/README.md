# 网络数据抓取工具

## 程序功能

用于通过互联网接口检索所需要的数据，并形成数据集。本工具主要针对百度搜索接口，支持动态参数搜索、批量搜索以及结果保存功能。

## 技术栈

- Python 3.x
- python -m venv (虚拟环境)
- requests (HTTP请求)
- beautifulsoup4 (HTML解析)

## 安装说明

1. 确保已安装Python 3.x
2. 克隆或下载本项目到本地
3. 创建并激活虚拟环境
   ```bash
   python -m venv venv
   # Windows
   venv\Scripts\activate
   # macOS/Linux
   source venv/bin/activate
   ```
4. 安装依赖包
   ```bash
   pip install requests beautifulsoup4
   ```

## 使用方法

1. 运行程序
   ```bash
   python baidu_spider.py
   ```

2. 功能说明
   - **单次搜索**: 输入搜索关键词，程序将显示百度搜索结果
   - **批量搜索**: 输入'b'，然后输入多个关键词（用逗号分隔），程序将批量搜索并保存结果
   - **退出程序**: 输入'q'退出

3. 输出格式
   - 控制台显示格式化的搜索结果
   - 可选择保存结果到文本文件，文件名为`baidu_search_result_时间戳.txt`或`baidu_search_results_时间戳.txt`

## 程序特性

- **动态参数支持**: 可自定义搜索关键词
- **User-Agent模拟**: 模拟浏览器请求，提高爬取成功率
- **错误处理**: 完善的异常捕获和错误提示
- **延迟控制**: 批量搜索时自动添加随机延迟，避免频繁请求
- **增强的数据提取**: 自动提取以下字段：
  - 标题（title）
  - 概要（summary）
  - URL链接（url）
  - 封面图片URL（cover_url）
- **智能数据获取**: 采用多重选择器策略，从多个可能的HTML元素中提取数据
- **封面图片处理**: 支持从多种图片元素中提取封面URL，并自动处理相对路径
- **百度百科提取**: 自动提取搜索结果中的百度百科信息（如果有）
- **相关搜索推荐**: 提取相关搜索关键词

## 注意事项

1. 本程序仅供学习和研究使用，请遵守相关网站的爬虫协议
2. 不要过度频繁地发送请求，以免给服务器造成压力
3. 部分搜索结果可能无法完全提取，这取决于百度搜索页面的结构变化
4. 若遇到验证码或IP限制，请暂停使用一段时间

## 扩展开发

如需扩展功能，可以考虑：
- 添加更多搜索引擎支持
- 实现代理IP池功能
- 添加验证码自动识别
- 支持更多数据格式输出（CSV、JSON等）
- 实现定时任务和增量爬取